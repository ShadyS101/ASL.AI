{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShadyS101/ASL.AI/blob/main/ASL_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sd5VZtRDpIi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "DATA_DIR = './'\n",
        "if not os.path.exists(DATA_DIR):\n",
        "    os.makedirs(DATA_DIR)\n",
        "\n",
        "number_of_classes = 3\n",
        "dataset_size = 150\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "for j in range(number_of_classes):\n",
        "    if not os.path.exists(os.path.join(DATA_DIR, str(j))):\n",
        "        os.makedirs(os.path.join(DATA_DIR, str(j)))\n",
        "\n",
        "    print('Collecting data for class {}'.format(j))\n",
        "\n",
        "    done = False\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        cv2.putText(frame, 'Ready? Press \"Q\" ! :)', (100, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3,\n",
        "                    cv2.LINE_AA)\n",
        "        cv2.imshow('frame', frame)\n",
        "        if cv2.waitKey(25) == ord('q'):\n",
        "            break\n",
        "\n",
        "    counter = 0\n",
        "    while counter < dataset_size:\n",
        "        ret, frame = cap.read()\n",
        "        cv2.imshow('frame', frame)\n",
        "        cv2.waitKey(25)\n",
        "        cv2.imwrite(os.path.join(DATA_DIR, str(j), '{}.jpg'.format(counter)), frame)\n",
        "\n",
        "        counter += 1\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "image_data=[]\n",
        "labels =[]\n",
        "\n",
        "for j in range(number_of_classes):\n",
        "    class_folder = os.path.join(DATA_DIR, str(j))\n",
        "\n",
        "    for filename in os.listdir(class_folder):\n",
        "        if filename.endswith('.jpg'):\n",
        "            image_path = os.path.join(class_folder, filename)\n",
        "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "            image = cv2.resize(image, (28, 28))\n",
        "            image_flat = image.flatten()\n",
        "            image_data.append(image_flat)\n",
        "            labels.append(j)\n",
        "\n",
        "image_data = np.array(image_data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# mu, sigma = 0, 0.1\n",
        "# noise = np.random.normal(mu, sigma, image_data.shape)\n",
        "\n",
        "df = pd.DataFrame(image_data)\n",
        "\n",
        "# df+=noise\n",
        "\n",
        "df['label'] = labels\n",
        "\n",
        "df.to_csv('sign_language.csv', index=False)\n",
        "\n",
        "print(\"Data has been saved to 'sign_language.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "\n",
        "train = pd.read_csv('sign_language.csv')\n",
        "test = pd.read_csv('sign_mnist_test.csv')\n",
        "\n",
        "print(train.head())\n",
        "\n",
        "x = train.drop('label',axis=1).values\n",
        "y=train['label'].values\n",
        "\n",
        "x=x.reshape(-1,28,28,1)\n",
        "\n",
        "x=x/255.0\n",
        "y = to_categorical(y, num_classes=26)\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(x, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(26, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_accuracy * 100}%')\n",
        "\n",
        "X_test = test.drop('label', axis=1).values\n",
        "y_test = test['label'].values\n",
        "\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "y_test = to_categorical(y_test, num_classes=26)\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_accuracy * 100}%')\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.resize(gray, (28, 28))\n",
        "    gray = gray / 255.0\n",
        "    gray = gray.reshape(1, 28, 28, 1)\n",
        "\n",
        "    prediction = model.predict(gray)\n",
        "    predicted_label = np.argmax(prediction)\n",
        "\n",
        "    cv2.putText(frame, f'Predicted: {chr(predicted_label + 65)}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "    cv2.imshow('Sign Language Recognition', frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "84N0cL4cDtrl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}